'use client';
import { useState, useEffect, useCallback, useRef } from 'react';
import {
  LiveKitRoom,
  RoomAudioRenderer,
  ControlBar,
  useParticipants,
  useRoomContext,
} from '@livekit/components-react';
import '@livekit/components-styles';
import { Track, RoomEvent, LocalParticipant, Participant } from 'livekit-client';

interface CallViewProps {
  roomId: number;
  token: string;
  livekitUrl: string;
  callType?: 'video' | 'audio';
  onClose: () => void;
  myLang?: string;
  otherLang?: string;
  authToken?: string;
}

export default function CallView({ roomId, token, livekitUrl, callType = 'video', onClose, myLang, otherLang, authToken }: CallViewProps) {
  const [isConnecting, setIsConnecting] = useState(true);
  if (!token || !livekitUrl) return null;

  return (
    <div style={{
      position: 'fixed', inset: 0, zIndex: 9999,
      background: '#0a0a0a', display: 'flex', flexDirection: 'column',
    }}>
      <div style={{
        display: 'flex', alignItems: 'center', justifyContent: 'space-between',
        padding: '12px 20px', background: 'rgba(0,0,0,0.8)', borderBottom: '1px solid #222',
      }}>
        <span style={{ color: '#fff', fontSize: 16, fontWeight: 600 }}>
          {isConnecting ? 'Connecting...' : callType === 'audio' ? 'üé§ Voice Call' : 'üìπ Video Call'}
        </span>
        <button onClick={onClose} style={{
          background: '#ef4444', color: '#fff', border: 'none', borderRadius: 8,
          padding: '8px 20px', fontSize: 14, fontWeight: 600, cursor: 'pointer',
        }}>End Call</button>
      </div>
      <div style={{ flex: 1, overflow: 'hidden' }}>
        <LiveKitRoom
          serverUrl={livekitUrl}
          token={token}
          connect={true}
          video={false}
          audio={false}
          onConnected={() => setIsConnecting(false)}
          onDisconnected={() => onClose()}
          onError={(err) => { console.error('LiveKit error:', err); }}
          style={{ height: '100%' }}
          data-lk-theme="default"
        >
          <CallContent
            callType={callType}
            onClose={onClose}
            roomId={roomId}
            myLang={myLang}
            otherLang={otherLang}
            authToken={authToken}
          />
          <RoomAudioRenderer />
        </LiveKitRoom>
      </div>
    </div>
  );
}

/* ‚îÄ‚îÄ‚îÄ Single video tile ‚îÄ‚îÄ‚îÄ */
function VideoTile({ participant, source, isLocal, isMain }: {
  participant: Participant; source: Track.Source; isLocal: boolean; isMain?: boolean;
}) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [hasVideo, setHasVideo] = useState(false);

  useEffect(() => {
    const el = videoRef.current;
    if (!el) return;
    const attach = () => {
      const pub = participant.getTrackPublication(source);
      if (pub?.track) {
        pub.track.attach(el);
        el.muted = true;
        el.play().catch(() => {});
        setHasVideo(true);
      } else {
        setHasVideo(false);
      }
    };
    attach();
    const interval = setInterval(attach, 500);
    return () => {
      clearInterval(interval);
      try {
        const pub = participant.getTrackPublication(source);
        if (pub?.track && el) pub.track.detach(el);
      } catch {}
    };
  }, [participant, source]);

  const isScreen = source === Track.Source.ScreenShare;
  const label = isScreen
    ? (isLocal ? 'üñ• Your Screen' : `üñ• ${participant.name || participant.identity}'s Screen`)
    : (isLocal ? 'You' : participant.name || participant.identity);

  return (
    <div style={{
      flex: isMain ? '1 1 100%' : '1 1 45%',
      maxWidth: '100%',
      position: 'relative', borderRadius: 12, overflow: 'hidden', background: '#111',
      minHeight: isMain ? 300 : 200,
      display: 'flex', alignItems: 'center', justifyContent: 'center',
      border: isScreen ? '2px solid #3b82f6' : 'none',
    }}>
      <video
        ref={videoRef}
        autoPlay playsInline muted
        style={{
          width: '100%', height: '100%',
          objectFit: isScreen ? 'contain' : 'cover',
          display: hasVideo ? 'block' : 'none',
          transform: (isLocal && !isScreen) ? 'scaleX(-1)' : 'none',
        }}
      />
      {!hasVideo && (
        <div style={{ textAlign: 'center', color: '#555' }}>
          <div style={{ fontSize: 40 }}>{isScreen ? 'üñ•' : 'üë§'}</div>
          <div style={{ fontSize: 13, marginTop: 4 }}>{label}</div>
        </div>
      )}
      <div style={{
        position: 'absolute', bottom: 8, left: 8,
        background: 'rgba(0,0,0,0.6)', color: '#fff',
        padding: '2px 8px', borderRadius: 6, fontSize: 12,
      }}>{label}</div>
    </div>
  );
}

/* ‚îÄ‚îÄ‚îÄ Subtitle overlay component ‚îÄ‚îÄ‚îÄ */
function SubtitleOverlay({ subtitles }: { subtitles: { original: string; translated: string; timestamp: number }[] }) {
  const now = Date.now();
  const visible = subtitles.filter(s => now - s.timestamp < 8000).slice(-3);
  if (visible.length === 0) return null;

  return (
    <div style={{
      position: 'absolute', bottom: 80, left: '50%', transform: 'translateX(-50%)',
      width: '80%', maxWidth: 700, zIndex: 50,
      display: 'flex', flexDirection: 'column', gap: 4, alignItems: 'center',
    }}>
      {visible.map((s, i) => {
        const age = now - s.timestamp;
        const opacity = age > 6000 ? Math.max(0, 1 - (age - 6000) / 2000) : 1;
        return (
          <div key={i} style={{
            background: 'rgba(0,0,0,0.75)', borderRadius: 10,
            padding: '8px 16px', textAlign: 'center', opacity,
            transition: 'opacity 0.5s',
            backdropFilter: 'blur(8px)',
          }}>
            {s.translated && s.translated !== s.original && (
              <div style={{ color: '#60a5fa', fontSize: 15, fontWeight: 600, lineHeight: 1.4 }}>
                {s.translated}
              </div>
            )}
            <div style={{ color: 'rgba(255,255,255,0.6)', fontSize: 12, lineHeight: 1.3, marginTop: s.translated ? 2 : 0 }}>
              {s.original}
            </div>
          </div>
        );
      })}
    </div>
  );
}

/* ‚îÄ‚îÄ‚îÄ Safe audio capture hook (never crashes the call) ‚îÄ‚îÄ‚îÄ */
function useAudioCapture(
  room: any,
  enabled: boolean,
  onAudioChunk: (base64: string) => void,
  intervalMs: number = 3000,
) {
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const intervalRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const streamRef = useRef<MediaStream | null>(null);

  useEffect(() => {
    if (!room || !enabled) return;
    let cancelled = false;

    const startCapture = async () => {
      try {
        // Check if MediaRecorder is supported
        if (typeof MediaRecorder === 'undefined') {
          console.warn('MediaRecorder not supported ‚Äî subtitles disabled');
          return;
        }

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true }).catch(() => null);
        if (!stream || cancelled) {
          if (stream) stream.getTracks().forEach(t => t.stop());
          return;
        }
        streamRef.current = stream;

        // Check if webm/opus is supported, fallback to default
        const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
          ? 'audio/webm;codecs=opus'
          : '';
        const options = mimeType ? { mimeType } : {};

        const createRecorder = () => {
          try {
            if (!streamRef.current?.active || cancelled) return;
            const recorder = new MediaRecorder(streamRef.current, options);
            mediaRecorderRef.current = recorder;
            chunksRef.current = [];

            recorder.ondataavailable = (event) => {
              try { if (event.data.size > 0) chunksRef.current.push(event.data); } catch {}
            };

            recorder.onstop = () => {
              try {
                if (chunksRef.current.length === 0 || cancelled) return;
                const blob = new Blob(chunksRef.current, { type: mimeType || 'audio/webm' });
                chunksRef.current = [];
                if (blob.size < 1000) return; // Skip silence

                const reader = new FileReader();
                reader.onloadend = () => {
                  try {
                    const base64 = (reader.result as string).split(',')[1];
                    if (base64) onAudioChunk(base64);
                  } catch {}
                };
                reader.readAsDataURL(blob);
              } catch {}
            };

            recorder.onerror = () => {}; // Silently handle recorder errors
            recorder.start();
          } catch (err) {
            console.warn('MediaRecorder creation failed:', err);
          }
        };

        createRecorder();

        intervalRef.current = setInterval(() => {
          try {
            if (mediaRecorderRef.current?.state === 'recording') {
              mediaRecorderRef.current.stop();
              setTimeout(createRecorder, 100);
            }
          } catch {}
        }, intervalMs);

      } catch (err) {
        console.warn('Audio capture setup failed (call continues normally):', err);
      }
    };

    const timer = setTimeout(startCapture, 2000);

    return () => {
      cancelled = true;
      clearTimeout(timer);
      try { if (intervalRef.current) clearInterval(intervalRef.current); } catch {}
      try { mediaRecorderRef.current?.stop(); } catch {}
      try { streamRef.current?.getTracks().forEach(t => t.stop()); } catch {}
    };
  }, [room, enabled, onAudioChunk, intervalMs]);
}

/* ‚îÄ‚îÄ‚îÄ Main call content with subtitles ‚îÄ‚îÄ‚îÄ */
function CallContent({ callType, onClose, roomId, myLang, otherLang, authToken }: {
  callType: string; onClose: () => void; roomId: number;
  myLang?: string; otherLang?: string; authToken?: string;
}) {
  const room = useRoomContext();
  const participants = useParticipants();
  const stableOnClose = useCallback(onClose, []);
  const [, forceUpdate] = useState(0);
  const [subtitlesEnabled, setSubtitlesEnabled] = useState(false); // Start OFF, enable after check
  const [subtitlesAvailable, setSubtitlesAvailable] = useState(false);
  const [subtitles, setSubtitles] = useState<{ original: string; translated: string; timestamp: number }[]>([]);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const consecutiveFailsRef = useRef(0);

  // Check if subtitle service is available on mount
  useEffect(() => {
    if (!authToken) return;
    fetch('/api/chat/call/subtitles/status', {
      headers: { Authorization: `Bearer ${authToken}` },
    })
      .then(r => r.ok ? r.json() : { available: false })
      .then(data => {
        if (data.available) {
          setSubtitlesAvailable(true);
          setSubtitlesEnabled(true); // Auto-enable if available
        }
      })
      .catch(() => {
        // Service check failed ‚Äî subtitles not available, call works fine
        setSubtitlesAvailable(false);
      });
  }, [authToken]);

  // Handle audio chunk ‚Äî send to backend
  const handleAudioChunk = useCallback(async (base64: string) => {
    if (!authToken || !myLang || consecutiveFailsRef.current >= 5) return;
    setIsTranscribing(true);
    try {
      const controller = new AbortController();
      const timeout = setTimeout(() => controller.abort(), 15000); // 15s frontend timeout

      const res = await fetch('/api/chat/call/transcribe', {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${authToken}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          audio: base64,
          source_lang: myLang,
          target_lang: otherLang || 'en',
          room_id: roomId,
        }),
        signal: controller.signal,
      });
      clearTimeout(timeout);

      if (res.ok) {
        const data = await res.json();
        consecutiveFailsRef.current = 0; // Reset on success
        if (data.originalText && data.originalText.trim()) {
          setSubtitles(prev => [...prev.slice(-10), {
            original: data.originalText,
            translated: data.translatedText,
            timestamp: Date.now(),
          }]);
        }
      } else {
        consecutiveFailsRef.current++;
      }
    } catch {
      consecutiveFailsRef.current++;
      // After 5 consecutive fails, auto-disable subtitles
      if (consecutiveFailsRef.current >= 5) {
        console.warn('Subtitles auto-disabled after 5 consecutive failures');
        setSubtitlesEnabled(false);
      }
    } finally {
      setIsTranscribing(false);
    }
  }, [authToken, myLang, otherLang, roomId]);

  // Capture audio when subtitles enabled
  useAudioCapture(room, subtitlesEnabled && subtitlesAvailable && !!authToken, handleAudioChunk, 3000);

  // Force re-render when tracks change
  useEffect(() => {
    if (!room) return;
    const refresh = () => forceUpdate(n => n + 1);
    room.on(RoomEvent.TrackSubscribed, refresh);
    room.on(RoomEvent.TrackUnsubscribed, refresh);
    room.on(RoomEvent.TrackPublished, refresh);
    room.on(RoomEvent.TrackUnpublished, refresh);
    room.on(RoomEvent.LocalTrackPublished, refresh);
    room.on(RoomEvent.LocalTrackUnpublished, refresh);
    return () => {
      room.off(RoomEvent.TrackSubscribed, refresh);
      room.off(RoomEvent.TrackUnsubscribed, refresh);
      room.off(RoomEvent.TrackPublished, refresh);
      room.off(RoomEvent.TrackUnpublished, refresh);
      room.off(RoomEvent.LocalTrackPublished, refresh);
      room.off(RoomEvent.LocalTrackUnpublished, refresh);
    };
  }, [room]);

  // Enable devices after connect
  useEffect(() => {
    if (!room) return;
    let cancelled = false;
    const enableDevices = async () => {
      try {
        await room.localParticipant.setMicrophoneEnabled(true);
      } catch (err) { console.warn('Mic failed:', err); }
      if (callType === 'video' && !cancelled) {
        try {
          const devices = await navigator.mediaDevices.enumerateDevices();
          const cameras = devices.filter(d => d.kind === 'videoinput');
          const realCam = cameras.find(c => !c.label.toLowerCase().includes('virtual'));
          if (realCam) {
            await room.localParticipant.setCameraEnabled(true, {
              deviceId: realCam.deviceId,
              resolution: { width: 1280, height: 720, frameRate: 30 },
            } as any);
          } else {
            await room.localParticipant.setCameraEnabled(true, {
              facingMode: 'user',
              resolution: { width: 1280, height: 720, frameRate: 30 },
            } as any);
          }
        } catch (err) { console.warn('Camera failed:', err); }
      }
    };
    const timer = setTimeout(enableDevices, 800);
    const handleDisconnect = () => stableOnClose();
    room.on(RoomEvent.Disconnected, handleDisconnect);
    return () => {
      cancelled = true;
      clearTimeout(timer);
      room.off(RoomEvent.Disconnected, handleDisconnect);
    };
  }, [room, callType, stableOnClose]);

  // Build tile list
  const tiles: { participant: Participant; source: Track.Source; isLocal: boolean }[] = [];
  const hasScreenShare = participants.some(p =>
    p.getTrackPublication(Track.Source.ScreenShare)?.track
  );
  participants.forEach(p => {
    const isLocal = p instanceof LocalParticipant;
    tiles.push({ participant: p, source: Track.Source.Camera, isLocal });
    if (p.getTrackPublication(Track.Source.ScreenShare)?.track) {
      tiles.push({ participant: p, source: Track.Source.ScreenShare, isLocal });
    }
  });

  return (
    <div style={{ height: '100%', display: 'flex', flexDirection: 'column', position: 'relative' }}>
      {/* Top bar info */}
      <div style={{
        position: 'absolute', top: 8, right: 16, display: 'flex', gap: 8, zIndex: 10,
      }}>
        <div style={{
          background: 'rgba(0,0,0,0.7)', color: '#fff',
          padding: '4px 10px', borderRadius: 12, fontSize: 12,
        }}>
          {participants.length} in call
        </div>

        {/* Subtitle toggle ‚Äî only show if service is available */}
        {subtitlesAvailable && (
          <button
            onClick={() => {
              setSubtitlesEnabled(!subtitlesEnabled);
              if (!subtitlesEnabled) consecutiveFailsRef.current = 0; // Reset failures on re-enable
            }}
            style={{
              background: subtitlesEnabled ? 'rgba(59,130,246,0.8)' : 'rgba(0,0,0,0.7)',
              color: '#fff', border: 'none', borderRadius: 12,
              padding: '4px 10px', fontSize: 12, cursor: 'pointer',
              display: 'flex', alignItems: 'center', gap: 4,
            }}
          >
            {subtitlesEnabled ? 'üî§ CC ON' : 'üî§ CC OFF'}
            {isTranscribing && subtitlesEnabled && (
              <span style={{ animation: 'pulse 1s infinite', fontSize: 8 }}>‚óè</span>
            )}
          </button>
        )}
      </div>

      {/* Video tiles */}
      {hasScreenShare ? (
        <div style={{ flex: 1, display: 'flex', flexDirection: 'column', gap: 8, padding: 8 }}>
          <div style={{ flex: 1 }}>
            {tiles.filter(t => t.source === Track.Source.ScreenShare).map(t => (
              <VideoTile key={`${t.participant.identity}-screen`} participant={t.participant} source={t.source} isLocal={t.isLocal} isMain />
            ))}
          </div>
          <div style={{ display: 'flex', gap: 8, height: 120 }}>
            {tiles.filter(t => t.source === Track.Source.Camera).map(t => (
              <VideoTile key={`${t.participant.identity}-cam`} participant={t.participant} source={t.source} isLocal={t.isLocal} />
            ))}
          </div>
        </div>
      ) : (
        <div style={{
          flex: 1, display: 'flex', flexWrap: 'wrap', gap: 8, padding: 8,
          alignItems: 'center', justifyContent: 'center',
        }}>
          {tiles.map(t => (
            <VideoTile key={`${t.participant.identity}-${t.source}`} participant={t.participant} source={t.source} isLocal={t.isLocal} />
          ))}
        </div>
      )}

      {/* Subtitle overlay ‚Äî only when enabled and available */}
      {subtitlesEnabled && subtitlesAvailable && <SubtitleOverlay subtitles={subtitles} />}

      <style>{`@keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.3; } }`}</style>

      <ControlBar
        variation="minimal"
        controls={{ camera: callType === 'video', microphone: true, screenShare: true, leave: true }}
      />
    </div>
  );
}
